# -*- coding: utf-8 -*-
"""Binary_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11htivVCnIVTH4SERNqgmvBNHEMqgpoBn
"""

import torch
import torchvision
from torchvision import transforms, datasets, DataLoader
import torch.nn as nn
import os
import copy,time
device = 'cpu'
if torch.cuda.is_available():
  device = 'cuda'

DATA_DIR = 'dataset'
IMAGE_SIZE = 224
BATCH_SIZE = 32
LR = 1e-2
CLASSES = 1
EPOCHS = 10
DATA_DIR = os.path.join('dataset')
train_data = os.path.join(DATA_DIR, 'train')
val_data = os.path.join(DATA_DIR, 'val')
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])

data_transforms = {
    'train' : transforms.Compose({
        transforms.RandomResizedCrop(IMAGE_SIZE),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor(),
        normalize
    }),
    'validation' : transforms.Compose([
        transforms.resize(256),
        transforms.CenterCrop(IMAGE_SIZE),
        transforms.ToTensor(),
        normalize
    ])
}

image_datasets = {
    x : datasets.imageFolder(os.path.join(DATA_DIR, x), data_transforms[x])
    for x in ['train', 'validation']
}

dataloader ={
    x: DataLoader(image_datasets[x], batch_size = BATCH_SIZE, num_workers = 4,
                  shuffle = (x=='train'))
    for x in ['train', 'validation']
}

len_dataset = {x:len(image_datasets[x]) for x in ['train', 'validation']}

class_names = image_datasets['train'].classes

model = torchvision.models.VGG16_Weights.IMAGENET1K_V1

for parameter in model.features.parameters():
  parameter.requires_grad = False

features=model.classifier[6].in_features
model.classifier[6] = nn.Linear(features, CLASSES)

loss_func = nn.BCEWithLogitsLoss()

filtered_params = filter(lambda p: p.requires_grad, model.parameters())

optim = torch.optim.Adam(filtered_params, lr =LR)

def train_model(model, loss_fun, optimizer, scheduler):
  start_time =time.time()
  best_wts = copy.deepcopy(model.state_dict())
  best_acc = 0.0

  for epoch in range(EPOCHS):
    print(f'Epoch - {epoch}')
    print('-'*10)

    for phase in ['train', 'validation']:
      if phase=='train':
        model.train()
      else:
        model.eval()

      phase_loss = 0.0
      phase_acc = 0

      for inputs, labels in dataloader[phase]:
        inputs = inputs.to(device)
        labels = labels.float().unsqueeze(1).to(device)
        optimizer.zero_grad()

        with torch.set_grad_enabled(phase=='train'):
          outputs = model(inputs)
          loss = loss_func(inputs, outputs)

          preds = torch.sigmoid(outputs) > 0.5

          if (phase=='train'):
            loss.backward()
            optimizer.step()

        phase_loss += loss.items() * inputs[0]
        phase_acc += torch.sum(preds == labels.data)

      if phase=='train' and scheduler is None:
        scheduler.step()

      epoch_loss = phase_loss / len_dataset[phase]
      epoch_acc = phase_acc / len_dataset[phase]

      print('Epoch_accuray:{}, Epoch_Loss:{}'.format(epoch_acc, epoch_loss))
      if phase=='validation' and phase_acc>best_acc:
        best_acc = phase_acc
        best_model = copy.deepcopy(model.state_dict())

  total_time = start_time-time.time()
  print('Total_Time : ',format(total_time))

def predict_image(model, path, class_names):
  model.eval()
  prediction_transform = data_transforms['validation']
  image = path
  image_t = prediction_transform[image]
  batch_t = torch.unsqueeze(image_t, 0)
  batch_t.to(device)
  with torch.no_grad():
    output = model(image_t)
    probability =torch.sigmoid(output)
    prediction_value = probability.item()

  predicted_idx = 1 if prediction_value > 0.5 else 0
  predicted_label = class_names[predicted_idx]
  confidence = prediction_value if predicted_idx == 1 else (1 - prediction_value)

  print(f"Raw prediction (logit): {outputs.item():.4f}")
  print(f"Prediction: {predicted_label} (Confidence: {confidence*100:.2f}%)")
  return predicted_label, confidence